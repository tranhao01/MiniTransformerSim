# ChatGPT Demo

This file illustrates a simple chat between a user and ChatGPT, included as a demonstration.

**User**: Hi! Can you explain what a Transformer is?

**Assistant**: A Transformer is a neural network architecture built from self attention and feed‑forward layers, arranged in an encoder-decoder structure. It excels at handling sequences such as natural language.

**User**: How does self attention work?

**Assistant**: Self attention allows each token to weigh the relevance of every other token in the sequence, forming contextual representations. It does this by computing Query, Key and Value vectors for each token and then combining them based on attention scores.
